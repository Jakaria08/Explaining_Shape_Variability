{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from reconstruction import AE\n",
    "from datasets import MeshData\n",
    "from utils import DataLoader\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import geomloss\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from scipy.stats import entropy\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier, KNeighborsRegressor\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE(\n",
       "  (en_layers): ModuleList(\n",
       "    (0): SpiralEnblock(\n",
       "      (conv): SpiralConv(3, 32, seq_length=9)\n",
       "    )\n",
       "    (1): SpiralEnblock(\n",
       "      (conv): SpiralConv(32, 32, seq_length=9)\n",
       "    )\n",
       "    (2): SpiralEnblock(\n",
       "      (conv): SpiralConv(32, 32, seq_length=9)\n",
       "    )\n",
       "    (3): SpiralEnblock(\n",
       "      (conv): SpiralConv(32, 64, seq_length=9)\n",
       "    )\n",
       "    (4): Linear(in_features=6272, out_features=24, bias=True)\n",
       "  )\n",
       "  (de_layers): ModuleList(\n",
       "    (0): Linear(in_features=12, out_features=6272, bias=True)\n",
       "    (1): SpiralDeblock(\n",
       "      (conv): SpiralConv(64, 64, seq_length=9)\n",
       "    )\n",
       "    (2): SpiralDeblock(\n",
       "      (conv): SpiralConv(64, 32, seq_length=9)\n",
       "    )\n",
       "    (3): SpiralDeblock(\n",
       "      (conv): SpiralConv(32, 32, seq_length=9)\n",
       "    )\n",
       "    (4): SpiralDeblock(\n",
       "      (conv): SpiralConv(32, 32, seq_length=9)\n",
       "    )\n",
       "    (5): SpiralConv(32, 3, seq_length=9)\n",
       "  )\n",
       "  (cls_sq): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       "  (reg_sq_2): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda', 1)\n",
    "# Set the path to the saved model directory\n",
    "#model_path = \"/home/jakaria/torus_bump_500_three_scale_binary_bump_variable_noise_fixed_angle/models_classification_regression_only_correlation_loss/models/65\"\n",
    "#model_path = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/torus/models_contrastive_inhib/146\"\n",
    "#model_path = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/torus/models_guided/30\"# Load the saved model\n",
    "model_path = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/torus/models_attribute/23\"\n",
    "model_state_dict = torch.load(f\"{model_path}/model_state_dict.pt\")\n",
    "in_channels = torch.load(f\"{model_path}/in_channels.pt\")\n",
    "out_channels = torch.load(f\"{model_path}/out_channels.pt\")\n",
    "latent_channels = torch.load(f\"{model_path}/latent_channels.pt\")\n",
    "spiral_indices_list = torch.load(f\"{model_path}/spiral_indices_list.pt\")\n",
    "up_transform_list = torch.load(f\"{model_path}/up_transform_list.pt\")\n",
    "down_transform_list = torch.load(f\"{model_path}/down_transform_list.pt\")\n",
    "std = torch.load(f\"{model_path}/std.pt\")\n",
    "mean = torch.load(f\"{model_path}/mean.pt\")\n",
    "template_face = torch.load(f\"{model_path}/faces.pt\")\n",
    "\n",
    "# Create an instance of the model\n",
    "model = AE(in_channels, out_channels, latent_channels,\n",
    "           spiral_indices_list, down_transform_list,\n",
    "           up_transform_list)\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.to(device)\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakaria/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "/home/jakaria/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing...\n",
      "Done!\n",
      "MSE of the KNN for thickness:  0.0012474324\n"
     ]
    }
   ],
   "source": [
    "template_fp = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/template/template.ply\"\n",
    "data_fp = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA\"\n",
    "test_exp = \"bareteeth\"\n",
    "split = \"interpolation\"\n",
    "\n",
    "meshdata = MeshData(data_fp,\n",
    "                    template_fp,\n",
    "                    split=split,\n",
    "                    test_exp=test_exp)\n",
    "\n",
    "train_loader = DataLoader(meshdata.train_dataset, batch_size=16)\n",
    "test_loader = DataLoader(meshdata.test_dataset, batch_size=16)\n",
    "\n",
    "angles_train = []\n",
    "thick_train = []\n",
    "latent_codes_train = []\n",
    "\n",
    "angles_test = []\n",
    "thick_test = []\n",
    "latent_codes_test = []\n",
    "\n",
    "test_original = []\n",
    "test_reconstructed = []\n",
    "\n",
    "single_latent = True\n",
    "#print(type(train_loader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(train_loader):\n",
    "        #print(\"train...\")\n",
    "        x = data.x.to(device)\n",
    "        y = data.y.to(device)\n",
    "        pred, mu, log_var, re, re2 = model(x)\n",
    "\n",
    "        z = model.reparameterize(mu, log_var)\n",
    "        if single_latent:\n",
    "            z = z[:,1]\n",
    "        latent_codes_train.append(z)\n",
    "        angles_train.append(y[:, :, 0])\n",
    "        thick_train.append(y[:, :, 2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        #print(\"test...\")\n",
    "        x = data.x.to(device)\n",
    "        y = data.y.to(device)\n",
    "        pred, mu, log_var, re, re2 = model(x)\n",
    "\n",
    "        z = model.reparameterize(mu, log_var)\n",
    "        if single_latent:\n",
    "            z = z[:,1]\n",
    "        latent_codes_test.append(z)\n",
    "        angles_test.append(y[:, :, 0])\n",
    "        thick_test.append(y[:, :, 2])\n",
    "\n",
    "        test_original.append(x)\n",
    "        test_reconstructed.append(pred)\n",
    "\n",
    "latent_codes_train = torch.cat(latent_codes_train)\n",
    "if single_latent:\n",
    "    latent_codes_train = latent_codes_train.cpu().numpy().reshape(-1, 1)\n",
    "else:\n",
    "    latent_codes_train = latent_codes_train.cpu().numpy()\n",
    "angles_train = torch.cat(angles_train).view(-1,1)\n",
    "angles_train = angles_train.view(-1).cpu().numpy()\n",
    "thick_train = torch.cat(thick_train).view(-1,1)\n",
    "thick_train = thick_train.view(-1).cpu().numpy()\n",
    "\n",
    "latent_codes_test = torch.cat(latent_codes_test)\n",
    "if single_latent:\n",
    "    latent_codes_test = latent_codes_test.cpu().numpy().reshape(-1, 1)\n",
    "else:   \n",
    "    latent_codes_test = latent_codes_test.cpu().numpy()\n",
    "angles_test = torch.cat(angles_test).view(-1,1)\n",
    "angles_test = angles_test.view(-1).cpu().numpy()\n",
    "thick_test = torch.cat(thick_test).view(-1,1)\n",
    "thick_test = thick_test.view(-1).cpu().numpy()\n",
    "\n",
    "test_original = torch.cat(test_original)\n",
    "#test_original = test_original.cpu().numpy()\n",
    "test_reconstructed = torch.cat(test_reconstructed)\n",
    "#test_reconstructed = test_reconstructed.cpu().numpy()\n",
    "\n",
    "# Train a classifier on the latent codes\n",
    "X_train = latent_codes_train\n",
    "y_train = thick_train\n",
    "X_test = latent_codes_test\n",
    "y_test = thick_test\n",
    "\n",
    "#knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn = KNeighborsRegressor(n_neighbors=12)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "#print(y_test[:10], y_pred[:10])\n",
    "#print(latent_codes_test[:10], y_test[:10])\n",
    "\n",
    "#print(y_test, y_pred)\n",
    "#print(\"Accuracy of the KNN for binary bump: \", accuracy_score(y_test, y_pred[:len(y_test)]))\n",
    "print(\"MSE of the KNN for thickness: \", mean_squared_error(y_test, y_pred[:len(y_test)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of the Linear Regression for thickness:  0.0017567916\n"
     ]
    }
   ],
   "source": [
    "LR = LinearRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "print(\"MSE of the Linear Regression for thickness: \", mean_squared_error(y_test, y_pred[:len(y_test)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emd_approx(sample, ref):\n",
    "    return geomloss.SamplesLoss()(sample, ref)\n",
    "\n",
    "\n",
    "def _pairwise_emd_cd_(sample_pcs, ref_pcs, batch_size):\n",
    "    print(\"computing Earth Mover and Chamfer distances\")\n",
    "    n_sample = sample_pcs.shape[0]\n",
    "    n_ref = ref_pcs.shape[0]\n",
    "    all_cd = []\n",
    "    all_emd = []\n",
    "    iterator = range(n_sample)\n",
    "    for sample_b_start in tqdm.tqdm(iterator):\n",
    "        sample_batch = sample_pcs[sample_b_start]\n",
    "\n",
    "        cd_lst = []\n",
    "        emd_lst = []\n",
    "        for ref_b_start in range(0, n_ref, batch_size):\n",
    "            ref_b_end = min(n_ref, ref_b_start + batch_size)\n",
    "            ref_batch = ref_pcs[ref_b_start:ref_b_end]\n",
    "\n",
    "            batch_size_ref = ref_batch.size(0)\n",
    "            sample_batch_exp = sample_batch.view(1, -1, 3).expand(\n",
    "                batch_size_ref, -1, -1)\n",
    "            sample_batch_exp = sample_batch_exp.contiguous()\n",
    "\n",
    "            cd_lst.append(chamfer_distance(sample_batch_exp, ref_batch,\n",
    "                          batch_reduction=None)[0].unsqueeze(0))\n",
    "\n",
    "            emd_batch = emd_approx(sample_batch_exp, ref_batch)\n",
    "            emd_lst.append(emd_batch.view(1, -1))\n",
    "\n",
    "        cd_lst = torch.cat(cd_lst, dim=-1)\n",
    "        emd_lst = torch.cat(emd_lst, dim=-1)\n",
    "        all_cd.append(cd_lst)\n",
    "        all_emd.append(emd_lst)\n",
    "\n",
    "    all_cd = torch.cat(all_cd, dim=0)  # n_sample, n_ref\n",
    "    all_emd = torch.cat(all_emd, dim=0)  # n_sample, n_ref\n",
    "    return all_cd, all_emd\n",
    "\n",
    "\n",
    "def knn(m_xx, m_xy, m_yy, k, sqrt=False):\n",
    "    n0 = m_xx.size(0)\n",
    "    n1 = m_yy.size(0)\n",
    "    label = torch.cat((torch.ones(n0), torch.zeros(n1))).to(m_xx)\n",
    "    mat = torch.cat((torch.cat((m_xx, m_xy), 1),\n",
    "                    torch.cat((m_xy.transpose(0, 1), m_yy), 1)), 0)\n",
    "    if sqrt:\n",
    "        mat = mat.abs().sqrt()\n",
    "\n",
    "    val, idx = (mat + torch.diag(\n",
    "        float('inf') * torch.ones(n0 + n1).to(m_xx))).topk(k, 0, False)\n",
    "\n",
    "    count = torch.zeros(n0 + n1).to(m_xx)\n",
    "    for i in range(0, k):\n",
    "        count = count + label.index_select(0, idx[i])\n",
    "    pred = torch.ge(count, (float(k) / 2) *\n",
    "                    torch.ones(n0 + n1).to(m_xx)).float()\n",
    "\n",
    "    s = {\n",
    "        'tp': (pred * label).sum(),\n",
    "        'fp': (pred * (1 - label)).sum(),\n",
    "        'fn': ((1 - pred) * label).sum(),\n",
    "        'tn': ((1 - pred) * (1 - label)).sum(),\n",
    "    }\n",
    "\n",
    "    s.update({\n",
    "        'precision': s['tp'] / (s['tp'] + s['fp'] + 1e-10),\n",
    "        'recall': s['tp'] / (s['tp'] + s['fn'] + 1e-10),\n",
    "        'acc_t': s['tp'] / (s['tp'] + s['fn'] + 1e-10),\n",
    "        'acc_f': s['tn'] / (s['tn'] + s['fp'] + 1e-10),\n",
    "        'acc': torch.eq(label, pred).float().mean(),\n",
    "    })\n",
    "    return s\n",
    "\n",
    "\n",
    "def lgan_mmd_cov(all_dist):\n",
    "    n_sample, n_ref = all_dist.size(0), all_dist.size(1)\n",
    "    min_val_fromsmp, min_idx = torch.min(all_dist, dim=1)\n",
    "    min_val, _ = torch.min(all_dist, dim=0)\n",
    "    mmd = min_val.mean()\n",
    "    mmd_smp = min_val_fromsmp.mean()\n",
    "    cov = float(min_idx.unique().view(-1).size(0)) / float(n_ref)\n",
    "    cov = torch.tensor(cov).to(all_dist)\n",
    "    return {\n",
    "        'lgan_mmd': mmd,\n",
    "        'lgan_cov': cov,\n",
    "        'lgan_mmd_smp': mmd_smp,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_all_metrics(sample_pcs, ref_pcs, batch_size):\n",
    "    results = {}\n",
    "\n",
    "    m_rs_cd, m_rs_emd = _pairwise_emd_cd_(sample_pcs, ref_pcs, batch_size)\n",
    "\n",
    "    res_cd = lgan_mmd_cov(m_rs_cd.t())\n",
    "    results.update({\n",
    "        \"%s-CD\" % k: v for k, v in res_cd.items()\n",
    "    })\n",
    "\n",
    "    res_emd = lgan_mmd_cov(m_rs_emd.t())\n",
    "    results.update({\n",
    "        \"%s-EMD\" % k: v for k, v in res_emd.items()\n",
    "    })\n",
    "\n",
    "    m_rr_cd, m_rr_emd = _pairwise_emd_cd_(ref_pcs, ref_pcs, batch_size)\n",
    "    m_ss_cd, m_ss_emd = _pairwise_emd_cd_(sample_pcs, sample_pcs, batch_size)\n",
    "\n",
    "    # 1-NN results\n",
    "    one_nn_cd_res = knn(m_rr_cd, m_rs_cd, m_ss_cd, 1, sqrt=False)\n",
    "    results.update({\n",
    "        \"1-NN-CD-%s\" % k: v for k, v in one_nn_cd_res.items() if 'acc' in k\n",
    "    })\n",
    "    one_nn_emd_res = knn(m_rr_emd, m_rs_emd, m_ss_emd, 1, sqrt=False)\n",
    "    results.update({\n",
    "        \"1-NN-EMD-%s\" % k: v for k, v in one_nn_emd_res.items() if 'acc' in k\n",
    "    })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing Earth Mover and Chamfer distances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/500 [00:53<3:43:04, 26.88s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompute_all_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_reconstructed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 95\u001b[0m, in \u001b[0;36mcompute_all_metrics\u001b[0;34m(sample_pcs, ref_pcs, batch_size)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_all_metrics\u001b[39m(sample_pcs, ref_pcs, batch_size):\n\u001b[1;32m     93\u001b[0m     results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 95\u001b[0m     m_rs_cd, m_rs_emd \u001b[38;5;241m=\u001b[39m \u001b[43m_pairwise_emd_cd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_pcs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_pcs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     res_cd \u001b[38;5;241m=\u001b[39m lgan_mmd_cov(m_rs_cd\u001b[38;5;241m.\u001b[39mt())\n\u001b[1;32m     98\u001b[0m     results\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m-CD\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m res_cd\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    100\u001b[0m     })\n",
      "Cell \u001b[0;32mIn[25], line 26\u001b[0m, in \u001b[0;36m_pairwise_emd_cd_\u001b[0;34m(sample_pcs, ref_pcs, batch_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m sample_batch_exp \u001b[38;5;241m=\u001b[39m sample_batch\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\n\u001b[1;32m     23\u001b[0m     batch_size_ref, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m sample_batch_exp \u001b[38;5;241m=\u001b[39m sample_batch_exp\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m---> 26\u001b[0m cd_lst\u001b[38;5;241m.\u001b[39mappend(\u001b[43mchamfer_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_batch_exp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m              \u001b[49m\u001b[43mbatch_reduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     29\u001b[0m emd_batch \u001b[38;5;241m=\u001b[39m emd_approx(sample_batch_exp, ref_batch)\n\u001b[1;32m     30\u001b[0m emd_lst\u001b[38;5;241m.\u001b[39mappend(emd_batch\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/pytorch3d/loss/chamfer.py:231\u001b[0m, in \u001b[0;36mchamfer_distance\u001b[0;34m(x, y, x_lengths, y_lengths, x_normals, y_normals, weights, batch_reduction, point_reduction, norm, single_directional, abs_cosine)\u001b[0m\n\u001b[1;32m    228\u001b[0m x, x_lengths, x_normals \u001b[38;5;241m=\u001b[39m _handle_pointcloud_input(x, x_lengths, x_normals)\n\u001b[1;32m    229\u001b[0m y, y_lengths, y_normals \u001b[38;5;241m=\u001b[39m _handle_pointcloud_input(y, y_lengths, y_normals)\n\u001b[0;32m--> 231\u001b[0m cham_x, cham_norm_x \u001b[38;5;241m=\u001b[39m \u001b[43m_chamfer_distance_single_direction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_normals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_normals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_reduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoint_reduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mabs_cosine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_directional:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cham_x, cham_norm_x\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/pytorch3d/loss/chamfer.py:116\u001b[0m, in \u001b[0;36m_chamfer_distance_single_direction\u001b[0;34m(x, y, x_lengths, y_lengths, x_normals, y_normals, weights, batch_reduction, point_reduction, norm, abs_cosine)\u001b[0m\n\u001b[1;32m    113\u001b[0m x_nn \u001b[38;5;241m=\u001b[39m knn_points(x, y, lengths1\u001b[38;5;241m=\u001b[39mx_lengths, lengths2\u001b[38;5;241m=\u001b[39my_lengths, norm\u001b[38;5;241m=\u001b[39mnorm, K\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    114\u001b[0m cham_x \u001b[38;5;241m=\u001b[39m x_nn\u001b[38;5;241m.\u001b[39mdists[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (N, P1)\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_x_heterogeneous:\n\u001b[1;32m    117\u001b[0m     cham_x[x_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compute_all_metrics(test_original, test_reconstructed, 16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
