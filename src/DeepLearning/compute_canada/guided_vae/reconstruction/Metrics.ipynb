{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakaria/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from reconstruction import AE\n",
    "from datasets import MeshData\n",
    "from utils import DataLoader\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import geomloss\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from scipy.stats import entropy\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier, KNeighborsRegressor\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE(\n",
       "  (en_layers): ModuleList(\n",
       "    (0): SpiralEnblock(\n",
       "      (conv): SpiralConv(3, 32, seq_length=9)\n",
       "    )\n",
       "    (1): SpiralEnblock(\n",
       "      (conv): SpiralConv(32, 32, seq_length=9)\n",
       "    )\n",
       "    (2): SpiralEnblock(\n",
       "      (conv): SpiralConv(32, 32, seq_length=9)\n",
       "    )\n",
       "    (3): SpiralEnblock(\n",
       "      (conv): SpiralConv(32, 64, seq_length=9)\n",
       "    )\n",
       "    (4): Linear(in_features=6272, out_features=24, bias=True)\n",
       "  )\n",
       "  (de_layers): ModuleList(\n",
       "    (0): Linear(in_features=12, out_features=6272, bias=True)\n",
       "    (1): SpiralDeblock(\n",
       "      (conv): SpiralConv(64, 64, seq_length=9)\n",
       "    )\n",
       "    (2): SpiralDeblock(\n",
       "      (conv): SpiralConv(64, 32, seq_length=9)\n",
       "    )\n",
       "    (3): SpiralDeblock(\n",
       "      (conv): SpiralConv(32, 32, seq_length=9)\n",
       "    )\n",
       "    (4): SpiralDeblock(\n",
       "      (conv): SpiralConv(32, 32, seq_length=9)\n",
       "    )\n",
       "    (5): SpiralConv(32, 3, seq_length=9)\n",
       "  )\n",
       "  (cls_sq): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       "  (reg_sq_2): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda', 1)\n",
    "# Set the path to the saved model directory\n",
    "#model_path = \"/home/jakaria/torus_bump_500_three_scale_binary_bump_variable_noise_fixed_angle/models_classification_regression_only_correlation_loss/models/65\"\n",
    "#model_path = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/torus/models_contrastive_inhib/146\"\n",
    "#model_path = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/torus/models_guided/30\"# Load the saved model\n",
    "model_path = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/torus/models_attribute/23\"\n",
    "model_state_dict = torch.load(f\"{model_path}/model_state_dict.pt\")\n",
    "in_channels = torch.load(f\"{model_path}/in_channels.pt\")\n",
    "out_channels = torch.load(f\"{model_path}/out_channels.pt\")\n",
    "latent_channels = torch.load(f\"{model_path}/latent_channels.pt\")\n",
    "spiral_indices_list = torch.load(f\"{model_path}/spiral_indices_list.pt\")\n",
    "up_transform_list = torch.load(f\"{model_path}/up_transform_list.pt\")\n",
    "down_transform_list = torch.load(f\"{model_path}/down_transform_list.pt\")\n",
    "std = torch.load(f\"{model_path}/std.pt\")\n",
    "mean = torch.load(f\"{model_path}/mean.pt\")\n",
    "template_face = torch.load(f\"{model_path}/faces.pt\")\n",
    "\n",
    "# Create an instance of the model\n",
    "model = AE(in_channels, out_channels, latent_channels,\n",
    "           spiral_indices_list, down_transform_list,\n",
    "           up_transform_list)\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.to(device)\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakaria/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "/home/jakaria/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing...\n",
      "Done!\n",
      "MSE of the KNN for thickness:  0.0012474324\n"
     ]
    }
   ],
   "source": [
    "template_fp = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/template/template.ply\"\n",
    "data_fp = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA\"\n",
    "test_exp = \"bareteeth\"\n",
    "split = \"interpolation\"\n",
    "\n",
    "meshdata = MeshData(data_fp,\n",
    "                    template_fp,\n",
    "                    split=split,\n",
    "                    test_exp=test_exp)\n",
    "\n",
    "train_loader = DataLoader(meshdata.train_dataset, batch_size=16)\n",
    "test_loader = DataLoader(meshdata.test_dataset, batch_size=16)\n",
    "\n",
    "angles_train = []\n",
    "thick_train = []\n",
    "latent_codes_train = []\n",
    "\n",
    "angles_test = []\n",
    "thick_test = []\n",
    "latent_codes_test = []\n",
    "\n",
    "test_original = []\n",
    "test_reconstructed = []\n",
    "latents_list = []\n",
    "\n",
    "single_latent = True\n",
    "#print(type(train_loader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(train_loader):\n",
    "        #print(\"train...\")\n",
    "        x = data.x.to(device)\n",
    "        y = data.y.to(device)\n",
    "        pred, mu, log_var, re, re2 = model(x)\n",
    "\n",
    "        z = model.reparameterize(mu, log_var)\n",
    "        if single_latent:\n",
    "            z = z[:,1]\n",
    "        latent_codes_train.append(z)\n",
    "        angles_train.append(y[:, :, 0])\n",
    "        thick_train.append(y[:, :, 2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        #print(\"test...\")\n",
    "        x = data.x.to(device)\n",
    "        y = data.y.to(device)\n",
    "        pred, mu, log_var, re, re2 = model(x)\n",
    "\n",
    "        z = model.reparameterize(mu, log_var)\n",
    "        if single_latent:\n",
    "            z = z[:,1]\n",
    "        latent_codes_test.append(z)\n",
    "        latents_list.append(z)\n",
    "        angles_test.append(y[:, :, 0])\n",
    "        thick_test.append(y[:, :, 2])\n",
    "\n",
    "        test_original.append(x)\n",
    "        test_reconstructed.append(pred)\n",
    "\n",
    "latent_codes_train = torch.cat(latent_codes_train)\n",
    "if single_latent:\n",
    "    latent_codes_train = latent_codes_train.cpu().numpy().reshape(-1, 1)\n",
    "else:\n",
    "    latent_codes_train = latent_codes_train.cpu().numpy()\n",
    "angles_train = torch.cat(angles_train).view(-1,1)\n",
    "angles_train = angles_train.view(-1).cpu().numpy()\n",
    "thick_train = torch.cat(thick_train).view(-1,1)\n",
    "thick_train = thick_train.view(-1).cpu().numpy()\n",
    "\n",
    "latent_codes_test = torch.cat(latent_codes_test)\n",
    "if single_latent:\n",
    "    latent_codes_test = latent_codes_test.cpu().numpy().reshape(-1, 1)\n",
    "else:   \n",
    "    latent_codes_test = latent_codes_test.cpu().numpy()\n",
    "angles_test = torch.cat(angles_test).view(-1,1)\n",
    "angles_test = angles_test.view(-1).cpu().numpy()\n",
    "thick_test = torch.cat(thick_test).view(-1,1)\n",
    "thick_test = thick_test.view(-1).cpu().numpy()\n",
    "\n",
    "# latent statistics\n",
    "latents = torch.cat(latents_list, dim=0)\n",
    "z_means = torch.mean(latents, dim=0)\n",
    "z_stds = torch.std(latents, dim=0)\n",
    "z_mins, _ = torch.min(latents, dim=0)\n",
    "z_maxs, _ = torch.max(latents, dim=0)\n",
    "z_stats = {'means': z_means, 'stds': z_stds,\n",
    "            'mins': z_mins, 'maxs': z_maxs}\n",
    "\n",
    "test_original = torch.cat(test_original)\n",
    "#test_original = test_original.cpu().numpy()\n",
    "test_reconstructed = torch.cat(test_reconstructed)\n",
    "#test_reconstructed = test_reconstructed.cpu().numpy()\n",
    "\n",
    "# Train a classifier on the latent codes\n",
    "X_train = latent_codes_train\n",
    "y_train = thick_train\n",
    "X_test = latent_codes_test\n",
    "y_test = thick_test\n",
    "\n",
    "#knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn = KNeighborsRegressor(n_neighbors=12)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "#print(y_test[:10], y_pred[:10])\n",
    "#print(latent_codes_test[:10], y_test[:10])\n",
    "\n",
    "#print(y_test, y_pred)\n",
    "#print(\"Accuracy of the KNN for binary bump: \", accuracy_score(y_test, y_pred[:len(y_test)]))\n",
    "print(\"MSE of the KNN for thickness: \", mean_squared_error(y_test, y_pred[:len(y_test)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of the Linear Regression for thickness:  0.0017567916\n"
     ]
    }
   ],
   "source": [
    "LR = LinearRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "print(\"MSE of the Linear Regression for thickness: \", mean_squared_error(y_test, y_pred[:len(y_test)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([32, 3496, 3])\n"
     ]
    }
   ],
   "source": [
    "test_original_small = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        #print(\"test...\")\n",
    "        x = data.x.to(device)\n",
    "        y = data.y.to(device)\n",
    "\n",
    "        test_original_small.append(x)\n",
    "        \n",
    "        if i == 1:\n",
    "            print(len(test_original_small))\n",
    "            break\n",
    "test_original_small = torch.cat(test_original_small)\n",
    "print(test_original_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_latent(n_samples, latent_dim=12):\n",
    "    z = torch.randn([n_samples, latent_dim])\n",
    "    z = z.to(device)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_generation(n_samples=16, latent_dim=12):\n",
    "    z = random_latent(n_samples, latent_dim=latent_dim)\n",
    "    gen_verts = model.decoder(z.to(device))\n",
    "    return gen_verts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emd_approx(sample, ref):\n",
    "    return geomloss.SamplesLoss()(sample, ref)\n",
    "\n",
    "\n",
    "def _pairwise_emd_cd_(sample_pcs, ref_pcs, batch_size):\n",
    "    print(\"computing Earth Mover and Chamfer distances\")\n",
    "    n_sample = sample_pcs.shape[0]\n",
    "    n_ref = ref_pcs.shape[0]\n",
    "    all_cd = []\n",
    "    all_emd = []\n",
    "    iterator = range(n_sample)\n",
    "    for sample_b_start in tqdm.tqdm(iterator):\n",
    "        sample_batch = sample_pcs[sample_b_start]\n",
    "\n",
    "        cd_lst = []\n",
    "        emd_lst = []\n",
    "        for ref_b_start in range(0, n_ref, batch_size):\n",
    "            ref_b_end = min(n_ref, ref_b_start + batch_size)\n",
    "            ref_batch = ref_pcs[ref_b_start:ref_b_end]\n",
    "\n",
    "            batch_size_ref = ref_batch.size(0)\n",
    "            sample_batch_exp = sample_batch.view(1, -1, 3).expand(\n",
    "                batch_size_ref, -1, -1)\n",
    "            sample_batch_exp = sample_batch_exp.contiguous()\n",
    "\n",
    "            cd_lst.append(chamfer_distance(sample_batch_exp, ref_batch,\n",
    "                          batch_reduction=None)[0].unsqueeze(0))\n",
    "\n",
    "            emd_batch = emd_approx(sample_batch_exp, ref_batch)\n",
    "            emd_lst.append(emd_batch.view(1, -1))\n",
    "\n",
    "        cd_lst = torch.cat(cd_lst, dim=-1)\n",
    "        emd_lst = torch.cat(emd_lst, dim=-1)\n",
    "        all_cd.append(cd_lst)\n",
    "        all_emd.append(emd_lst)\n",
    "\n",
    "    all_cd = torch.cat(all_cd, dim=0)  # n_sample, n_ref\n",
    "    all_emd = torch.cat(all_emd, dim=0)  # n_sample, n_ref\n",
    "    return all_cd, all_emd\n",
    "\n",
    "\n",
    "def knn(m_xx, m_xy, m_yy, k, sqrt=False):\n",
    "    n0 = m_xx.size(0)\n",
    "    n1 = m_yy.size(0)\n",
    "    label = torch.cat((torch.ones(n0), torch.zeros(n1))).to(m_xx)\n",
    "    mat = torch.cat((torch.cat((m_xx, m_xy), 1),\n",
    "                    torch.cat((m_xy.transpose(0, 1), m_yy), 1)), 0)\n",
    "    if sqrt:\n",
    "        mat = mat.abs().sqrt()\n",
    "\n",
    "    val, idx = (mat + torch.diag(\n",
    "        float('inf') * torch.ones(n0 + n1).to(m_xx))).topk(k, 0, False)\n",
    "\n",
    "    count = torch.zeros(n0 + n1).to(m_xx)\n",
    "    for i in range(0, k):\n",
    "        count = count + label.index_select(0, idx[i])\n",
    "    pred = torch.ge(count, (float(k) / 2) *\n",
    "                    torch.ones(n0 + n1).to(m_xx)).float()\n",
    "\n",
    "    s = {\n",
    "        'tp': (pred * label).sum(),\n",
    "        'fp': (pred * (1 - label)).sum(),\n",
    "        'fn': ((1 - pred) * label).sum(),\n",
    "        'tn': ((1 - pred) * (1 - label)).sum(),\n",
    "    }\n",
    "\n",
    "    s.update({\n",
    "        'precision': s['tp'] / (s['tp'] + s['fp'] + 1e-10),\n",
    "        'recall': s['tp'] / (s['tp'] + s['fn'] + 1e-10),\n",
    "        'acc_t': s['tp'] / (s['tp'] + s['fn'] + 1e-10),\n",
    "        'acc_f': s['tn'] / (s['tn'] + s['fp'] + 1e-10),\n",
    "        'acc': torch.eq(label, pred).float().mean(),\n",
    "    })\n",
    "    return s\n",
    "\n",
    "\n",
    "def lgan_mmd_cov(all_dist):\n",
    "    n_sample, n_ref = all_dist.size(0), all_dist.size(1)\n",
    "    min_val_fromsmp, min_idx = torch.min(all_dist, dim=1)\n",
    "    min_val, _ = torch.min(all_dist, dim=0)\n",
    "    mmd = min_val.mean()\n",
    "    mmd_smp = min_val_fromsmp.mean()\n",
    "    cov = float(min_idx.unique().view(-1).size(0)) / float(n_ref)\n",
    "    cov = torch.tensor(cov).to(all_dist)\n",
    "    return {\n",
    "        'lgan_mmd': mmd,\n",
    "        'lgan_cov': cov,\n",
    "        'lgan_mmd_smp': mmd_smp,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_all_metrics(sample_pcs, ref_pcs, batch_size):\n",
    "    results = {}\n",
    "\n",
    "    m_rs_cd, m_rs_emd = _pairwise_emd_cd_(sample_pcs, ref_pcs, batch_size)\n",
    "    '''\n",
    "    res_cd = lgan_mmd_cov(m_rs_cd.t())\n",
    "    results.update({\n",
    "        \"%s-CD\" % k: v for k, v in res_cd.items()\n",
    "    })\n",
    "\n",
    "    res_emd = lgan_mmd_cov(m_rs_emd.t())\n",
    "    results.update({\n",
    "        \"%s-EMD\" % k: v for k, v in res_emd.items()\n",
    "    })\n",
    "    '''\n",
    "    m_rr_cd, m_rr_emd = _pairwise_emd_cd_(ref_pcs, ref_pcs, batch_size)\n",
    "    m_ss_cd, m_ss_emd = _pairwise_emd_cd_(sample_pcs, sample_pcs, batch_size)\n",
    "    \n",
    "    # 1-NN results\n",
    "    one_nn_cd_res = knn(m_rr_cd, m_rs_cd, m_ss_cd, 1, sqrt=False)\n",
    "    results.update({\n",
    "        \"1-NN-CD-%s\" % k: v for k, v in one_nn_cd_res.items() if 'acc' in k\n",
    "    })\n",
    "    one_nn_emd_res = knn(m_rr_emd, m_rs_emd, m_ss_emd, 1, sqrt=False)\n",
    "    results.update({\n",
    "        \"1-NN-EMD-%s\" % k: v for k, v in one_nn_emd_res.items() if 'acc' in k\n",
    "    })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3496, 3])\n"
     ]
    }
   ],
   "source": [
    "random_generation = random_generation(n_samples=32, latent_dim=12)\n",
    "print(random_generation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing Earth Mover and Chamfer distances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 6/32 [00:09<00:40,  1.56s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 746.00 MiB (GPU 1; 23.64 GiB total capacity; 22.27 GiB already allocated; 503.56 MiB free; 22.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m restults \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_all_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_generation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_original_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(restults)\n",
      "Cell \u001b[0;32mIn[7], line 95\u001b[0m, in \u001b[0;36mcompute_all_metrics\u001b[0;34m(sample_pcs, ref_pcs, batch_size)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_all_metrics\u001b[39m(sample_pcs, ref_pcs, batch_size):\n\u001b[1;32m     93\u001b[0m     results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 95\u001b[0m     m_rs_cd, m_rs_emd \u001b[38;5;241m=\u001b[39m \u001b[43m_pairwise_emd_cd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_pcs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_pcs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m    res_cd = lgan_mmd_cov(m_rs_cd.t())\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    results.update({\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    })\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     m_rr_cd, m_rr_emd \u001b[38;5;241m=\u001b[39m _pairwise_emd_cd_(ref_pcs, ref_pcs, batch_size)\n",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m, in \u001b[0;36m_pairwise_emd_cd_\u001b[0;34m(sample_pcs, ref_pcs, batch_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m     sample_batch_exp \u001b[38;5;241m=\u001b[39m sample_batch_exp\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     26\u001b[0m     cd_lst\u001b[38;5;241m.\u001b[39mappend(chamfer_distance(sample_batch_exp, ref_batch,\n\u001b[1;32m     27\u001b[0m                   batch_reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 29\u001b[0m     emd_batch \u001b[38;5;241m=\u001b[39m \u001b[43memd_approx\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_batch_exp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     emd_lst\u001b[38;5;241m.\u001b[39mappend(emd_batch\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     32\u001b[0m cd_lst \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(cd_lst, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m, in \u001b[0;36memd_approx\u001b[0;34m(sample, ref)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21memd_approx\u001b[39m(sample, ref):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeomloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSamplesLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/geomloss/samples_loss.py:265\u001b[0m, in \u001b[0;36mSamplesLoss.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    262\u001b[0m     α, x, β, y \u001b[38;5;241m=\u001b[39m α\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), β\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), y\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# Run --------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[43mroutines\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mα\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mβ\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblur\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblur\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreach\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiameter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiameter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcluster_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpotentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpotentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Make sure that the output has the correct shape ------------------------------------\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpotentials\n\u001b[1;32m    289\u001b[0m ):  \u001b[38;5;66;03m# Return some dual potentials (= test functions) sampled on the input measures\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/geomloss/sinkhorn_samples.py:196\u001b[0m, in \u001b[0;36msinkhorn_tensorized\u001b[0;34m(a, x, b, y, p, blur, reach, diameter, scaling, cost, debias, potentials, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m diameter, eps, eps_list, rho \u001b[38;5;241m=\u001b[39m scaling_parameters(\n\u001b[1;32m    192\u001b[0m     x, y, p, blur, reach, diameter, scaling\n\u001b[1;32m    193\u001b[0m )\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# Use an optimal transport solver to retrieve the dual potentials:\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m f_aa, g_bb, g_ab, f_ba \u001b[38;5;241m=\u001b[39m \u001b[43msinkhorn_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43msoftmin_tensorized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC_xx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC_yy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC_xy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC_yx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# Optimal transport cost:\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sinkhorn_cost(\n\u001b[1;32m    211\u001b[0m     eps,\n\u001b[1;32m    212\u001b[0m     rho,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m     potentials\u001b[38;5;241m=\u001b[39mpotentials,\n\u001b[1;32m    222\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/geomloss/sinkhorn_divergence.py:622\u001b[0m, in \u001b[0;36msinkhorn_loop\u001b[0;34m(softmin, a_logs, b_logs, C_xxs, C_yys, C_xys, C_yxs, eps_list, rho, jumps, kernel_truncation, truncate, cost, extrapolate, debias, last_extrapolation)\u001b[0m\n\u001b[1;32m    616\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last_extrapolation:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# The cross-updates should be done in parallel!\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     f_ba, g_ab \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    621\u001b[0m         damping \u001b[38;5;241m*\u001b[39m softmin(eps, C_xy, (b_log \u001b[38;5;241m+\u001b[39m g_ab \u001b[38;5;241m/\u001b[39m eps)\u001b[38;5;241m.\u001b[39mdetach()),\n\u001b[0;32m--> 622\u001b[0m         damping \u001b[38;5;241m*\u001b[39m \u001b[43msoftmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_yx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_log\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mf_ba\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    623\u001b[0m     )\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debias:\n\u001b[1;32m    626\u001b[0m         f_aa \u001b[38;5;241m=\u001b[39m damping \u001b[38;5;241m*\u001b[39m softmin(eps, C_xx, (a_log \u001b[38;5;241m+\u001b[39m f_aa \u001b[38;5;241m/\u001b[39m eps)\u001b[38;5;241m.\u001b[39mdetach())\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/geomloss/sinkhorn_samples.py:72\u001b[0m, in \u001b[0;36msoftmin_tensorized\u001b[0;34m(eps, C_xy, h_y)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Soft-C-transform, implemented using dense torch Tensors.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03mThis routine implements the (soft-)C-transform\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m        by the points :math:`x_i`.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m B \u001b[38;5;241m=\u001b[39m C_xy\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39meps \u001b[38;5;241m*\u001b[39m (\u001b[43mh_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mC_xy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m)\u001b[38;5;241m.\u001b[39mlogsumexp(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mview(B, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 746.00 MiB (GPU 1; 23.64 GiB total capacity; 22.27 GiB already allocated; 503.56 MiB free; 22.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "restults = compute_all_metrics(random_generation, test_original_small, 16)\n",
    "print(restults)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
