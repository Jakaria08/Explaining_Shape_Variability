{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from reconstruction import AE\n",
    "from datasets import MeshData\n",
    "from utils import DataLoader\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import geomloss\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from scipy.stats import entropy\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier, KNeighborsRegressor\n",
    "from numpy.linalg import norm\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE(\n",
       "  (en_layers): ModuleList(\n",
       "    (0): SpiralEnblock(\n",
       "      (conv): SpiralConv(3, 32, seq_length=9)\n",
       "    )\n",
       "    (1): SpiralEnblock(\n",
       "      (conv): SpiralConv(32, 32, seq_length=9)\n",
       "    )\n",
       "    (2): SpiralEnblock(\n",
       "      (conv): SpiralConv(32, 32, seq_length=9)\n",
       "    )\n",
       "    (3): SpiralEnblock(\n",
       "      (conv): SpiralConv(32, 64, seq_length=9)\n",
       "    )\n",
       "    (4): Linear(in_features=6272, out_features=24, bias=True)\n",
       "  )\n",
       "  (de_layers): ModuleList(\n",
       "    (0): Linear(in_features=12, out_features=6272, bias=True)\n",
       "    (1): SpiralDeblock(\n",
       "      (conv): SpiralConv(64, 64, seq_length=9)\n",
       "    )\n",
       "    (2): SpiralDeblock(\n",
       "      (conv): SpiralConv(64, 32, seq_length=9)\n",
       "    )\n",
       "    (3): SpiralDeblock(\n",
       "      (conv): SpiralConv(32, 32, seq_length=9)\n",
       "    )\n",
       "    (4): SpiralDeblock(\n",
       "      (conv): SpiralConv(32, 32, seq_length=9)\n",
       "    )\n",
       "    (5): SpiralConv(32, 3, seq_length=9)\n",
       "  )\n",
       "  (cls_sq): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       "  (reg_sq_2): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda', 1)\n",
    "# Set the path to the saved model directory\n",
    "#model_path = \"/home/jakaria/torus_bump_500_three_scale_binary_bump_variable_noise_fixed_angle/models_classification_regression_only_correlation_loss/models/65\"\n",
    "#model_path = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/torus/models_contrastive_inhib/146\"\n",
    "#model_path = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/torus/models_guided/30\"# Load the saved model\n",
    "model_path = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/torus/models_attribute/23\"\n",
    "model_state_dict = torch.load(f\"{model_path}/model_state_dict.pt\")\n",
    "in_channels = torch.load(f\"{model_path}/in_channels.pt\")\n",
    "out_channels = torch.load(f\"{model_path}/out_channels.pt\")\n",
    "latent_channels = torch.load(f\"{model_path}/latent_channels.pt\")\n",
    "spiral_indices_list = torch.load(f\"{model_path}/spiral_indices_list.pt\")\n",
    "up_transform_list = torch.load(f\"{model_path}/up_transform_list.pt\")\n",
    "down_transform_list = torch.load(f\"{model_path}/down_transform_list.pt\")\n",
    "std = torch.load(f\"{model_path}/std.pt\")\n",
    "mean = torch.load(f\"{model_path}/mean.pt\")\n",
    "template_face = torch.load(f\"{model_path}/faces.pt\")\n",
    "\n",
    "# Create an instance of the model\n",
    "model = AE(in_channels, out_channels, latent_channels,\n",
    "           spiral_indices_list, down_transform_list,\n",
    "           up_transform_list)\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.to(device)\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakaria/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "/home/jakaria/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing...\n",
      "Done!\n",
      "<class 'utils.dataloader.DataLoader'>\n",
      "MSE of the KNN for thickness:  0.0012474324\n"
     ]
    }
   ],
   "source": [
    "template_fp = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/template/template.ply\"\n",
    "data_fp = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA\"\n",
    "test_exp = \"bareteeth\"\n",
    "split = \"interpolation\"\n",
    "\n",
    "meshdata = MeshData(data_fp,\n",
    "                    template_fp,\n",
    "                    split=split,\n",
    "                    test_exp=test_exp)\n",
    "\n",
    "train_loader = DataLoader(meshdata.train_dataset, batch_size=16)\n",
    "test_loader = DataLoader(meshdata.test_dataset, batch_size=16)\n",
    "\n",
    "angles_train = []\n",
    "thick_train = []\n",
    "latent_codes_train = []\n",
    "\n",
    "angles_test = []\n",
    "thick_test = []\n",
    "latent_codes_test = []\n",
    "\n",
    "single_latent = True\n",
    "#print(type(train_loader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(train_loader):\n",
    "        #print(\"train...\")\n",
    "        x = data.x.to(device)\n",
    "        y = data.y.to(device)\n",
    "        pred, mu, log_var, re, re2 = model(x)\n",
    "\n",
    "        z = model.reparameterize(mu, log_var)\n",
    "        if single_latent:\n",
    "            z = z[:,1]\n",
    "        latent_codes_train.append(z)\n",
    "        angles_train.append(y[:, :, 0])\n",
    "        thick_train.append(y[:, :, 2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        #print(\"test...\")\n",
    "        x = data.x.to(device)\n",
    "        y = data.y.to(device)\n",
    "        pred, mu, log_var, re, re2 = model(x)\n",
    "\n",
    "        z = model.reparameterize(mu, log_var)\n",
    "        if single_latent:\n",
    "            z = z[:,1]\n",
    "        latent_codes_test.append(z)\n",
    "        angles_test.append(y[:, :, 0])\n",
    "        thick_test.append(y[:, :, 2])\n",
    "\n",
    "latent_codes_train = torch.cat(latent_codes_train)\n",
    "if single_latent:\n",
    "    latent_codes_train = latent_codes_train.cpu().numpy().reshape(-1, 1)\n",
    "else:\n",
    "    latent_codes_train = latent_codes_train.cpu().numpy()\n",
    "angles_train = torch.cat(angles_train).view(-1,1)\n",
    "angles_train = angles_train.view(-1).cpu().numpy()\n",
    "thick_train = torch.cat(thick_train).view(-1,1)\n",
    "thick_train = thick_train.view(-1).cpu().numpy()\n",
    "\n",
    "latent_codes_test = torch.cat(latent_codes_test)\n",
    "if single_latent:\n",
    "    latent_codes_test = latent_codes_test.cpu().numpy().reshape(-1, 1)\n",
    "else:   \n",
    "    latent_codes_test = latent_codes_test.cpu().numpy()\n",
    "angles_test = torch.cat(angles_test).view(-1,1)\n",
    "angles_test = angles_test.view(-1).cpu().numpy()\n",
    "thick_test = torch.cat(thick_test).view(-1,1)\n",
    "thick_test = thick_test.view(-1).cpu().numpy()\n",
    "\n",
    "# Train a classifier on the latent codes\n",
    "X_train = latent_codes_train\n",
    "y_train = thick_train\n",
    "X_test = latent_codes_test\n",
    "y_test = thick_test\n",
    "\n",
    "#knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn = KNeighborsRegressor(n_neighbors=12)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "#print(y_test[:10], y_pred[:10])\n",
    "#print(latent_codes_test[:10], y_test[:10])\n",
    "\n",
    "#print(y_test, y_pred)\n",
    "#print(\"Accuracy of the KNN for binary bump: \", accuracy_score(y_test, y_pred[:len(y_test)]))\n",
    "print(\"MSE of the KNN for thickness: \", mean_squared_error(y_test, y_pred[:len(y_test)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of the Linear Regression for thickness:  0.0017567916\n"
     ]
    }
   ],
   "source": [
    "LR = LinearRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "print(\"MSE of the Linear Regression for thickness: \", mean_squared_error(y_test, y_pred[:len(y_test)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emd_approx(sample, ref):\n",
    "    return geomloss.SamplesLoss()(sample, ref)\n",
    "\n",
    "\n",
    "def _pairwise_emd_cd_(sample_pcs, ref_pcs, batch_size):\n",
    "    print(\"computing Earth Mover and Chamfer distances\")\n",
    "    n_sample = sample_pcs.shape[0]\n",
    "    n_ref = ref_pcs.shape[0]\n",
    "    all_cd = []\n",
    "    all_emd = []\n",
    "    iterator = range(n_sample)\n",
    "    for sample_b_start in tqdm.tqdm(iterator):\n",
    "        sample_batch = sample_pcs[sample_b_start]\n",
    "\n",
    "        cd_lst = []\n",
    "        emd_lst = []\n",
    "        for ref_b_start in range(0, n_ref, batch_size):\n",
    "            ref_b_end = min(n_ref, ref_b_start + batch_size)\n",
    "            ref_batch = ref_pcs[ref_b_start:ref_b_end]\n",
    "\n",
    "            batch_size_ref = ref_batch.size(0)\n",
    "            sample_batch_exp = sample_batch.view(1, -1, 3).expand(\n",
    "                batch_size_ref, -1, -1)\n",
    "            sample_batch_exp = sample_batch_exp.contiguous()\n",
    "\n",
    "            cd_lst.append(chamfer_distance(sample_batch_exp, ref_batch,\n",
    "                          batch_reduction=None)[0].unsqueeze(0))\n",
    "\n",
    "            emd_batch = emd_approx(sample_batch_exp, ref_batch)\n",
    "            emd_lst.append(emd_batch.view(1, -1))\n",
    "\n",
    "        cd_lst = torch.cat(cd_lst, dim=-1)\n",
    "        emd_lst = torch.cat(emd_lst, dim=-1)\n",
    "        all_cd.append(cd_lst)\n",
    "        all_emd.append(emd_lst)\n",
    "\n",
    "    all_cd = torch.cat(all_cd, dim=0)  # n_sample, n_ref\n",
    "    all_emd = torch.cat(all_emd, dim=0)  # n_sample, n_ref\n",
    "    return all_cd, all_emd\n",
    "\n",
    "\n",
    "def knn(m_xx, m_xy, m_yy, k, sqrt=False):\n",
    "    n0 = m_xx.size(0)\n",
    "    n1 = m_yy.size(0)\n",
    "    label = torch.cat((torch.ones(n0), torch.zeros(n1))).to(m_xx)\n",
    "    mat = torch.cat((torch.cat((m_xx, m_xy), 1),\n",
    "                    torch.cat((m_xy.transpose(0, 1), m_yy), 1)), 0)\n",
    "    if sqrt:\n",
    "        mat = mat.abs().sqrt()\n",
    "\n",
    "    val, idx = (mat + torch.diag(\n",
    "        float('inf') * torch.ones(n0 + n1).to(m_xx))).topk(k, 0, False)\n",
    "\n",
    "    count = torch.zeros(n0 + n1).to(m_xx)\n",
    "    for i in range(0, k):\n",
    "        count = count + label.index_select(0, idx[i])\n",
    "    pred = torch.ge(count, (float(k) / 2) *\n",
    "                    torch.ones(n0 + n1).to(m_xx)).float()\n",
    "\n",
    "    s = {\n",
    "        'tp': (pred * label).sum(),\n",
    "        'fp': (pred * (1 - label)).sum(),\n",
    "        'fn': ((1 - pred) * label).sum(),\n",
    "        'tn': ((1 - pred) * (1 - label)).sum(),\n",
    "    }\n",
    "\n",
    "    s.update({\n",
    "        'precision': s['tp'] / (s['tp'] + s['fp'] + 1e-10),\n",
    "        'recall': s['tp'] / (s['tp'] + s['fn'] + 1e-10),\n",
    "        'acc_t': s['tp'] / (s['tp'] + s['fn'] + 1e-10),\n",
    "        'acc_f': s['tn'] / (s['tn'] + s['fp'] + 1e-10),\n",
    "        'acc': torch.eq(label, pred).float().mean(),\n",
    "    })\n",
    "    return s\n",
    "\n",
    "\n",
    "def lgan_mmd_cov(all_dist):\n",
    "    n_sample, n_ref = all_dist.size(0), all_dist.size(1)\n",
    "    min_val_fromsmp, min_idx = torch.min(all_dist, dim=1)\n",
    "    min_val, _ = torch.min(all_dist, dim=0)\n",
    "    mmd = min_val.mean()\n",
    "    mmd_smp = min_val_fromsmp.mean()\n",
    "    cov = float(min_idx.unique().view(-1).size(0)) / float(n_ref)\n",
    "    cov = torch.tensor(cov).to(all_dist)\n",
    "    return {\n",
    "        'lgan_mmd': mmd,\n",
    "        'lgan_cov': cov,\n",
    "        'lgan_mmd_smp': mmd_smp,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_all_metrics(sample_pcs, ref_pcs, batch_size):\n",
    "    results = {}\n",
    "\n",
    "    m_rs_cd, m_rs_emd = _pairwise_emd_cd_(sample_pcs, ref_pcs, batch_size)\n",
    "\n",
    "    res_cd = lgan_mmd_cov(m_rs_cd.t())\n",
    "    results.update({\n",
    "        \"%s-CD\" % k: v for k, v in res_cd.items()\n",
    "    })\n",
    "\n",
    "    res_emd = lgan_mmd_cov(m_rs_emd.t())\n",
    "    results.update({\n",
    "        \"%s-EMD\" % k: v for k, v in res_emd.items()\n",
    "    })\n",
    "\n",
    "    m_rr_cd, m_rr_emd = _pairwise_emd_cd_(ref_pcs, ref_pcs, batch_size)\n",
    "    m_ss_cd, m_ss_emd = _pairwise_emd_cd_(sample_pcs, sample_pcs, batch_size)\n",
    "\n",
    "    # 1-NN results\n",
    "    one_nn_cd_res = knn(m_rr_cd, m_rs_cd, m_ss_cd, 1, sqrt=False)\n",
    "    results.update({\n",
    "        \"1-NN-CD-%s\" % k: v for k, v in one_nn_cd_res.items() if 'acc' in k\n",
    "    })\n",
    "    one_nn_emd_res = knn(m_rr_emd, m_rs_emd, m_ss_emd, 1, sqrt=False)\n",
    "    results.update({\n",
    "        \"1-NN-EMD-%s\" % k: v for k, v in one_nn_emd_res.items() if 'acc' in k\n",
    "    })\n",
    "\n",
    "    return results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
