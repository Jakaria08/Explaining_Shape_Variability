{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from reconstruction import AE\n",
    "from datasets import MeshData\n",
    "from utils import utils, DataLoader, mesh_sampling, sap\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from skimage import measure\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, FloatSlider\n",
    "from IPython.display import display\n",
    "import meshplot as mp\n",
    "import os, sys\n",
    "from math import ceil\n",
    "from scipy.ndimage import zoom\n",
    "import open3d as o3d\n",
    "from scipy.spatial import ConvexHull\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meshplot left an annoying print statement in their code. Using this context manager to supress it...\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE(\n",
       "  (en_layers): ModuleList(\n",
       "    (0): SpiralEnblock(\n",
       "      (conv): SpiralConv(3, 16, seq_length=9)\n",
       "    )\n",
       "    (1-2): 2 x SpiralEnblock(\n",
       "      (conv): SpiralConv(16, 16, seq_length=9)\n",
       "    )\n",
       "    (3): SpiralEnblock(\n",
       "      (conv): SpiralConv(16, 32, seq_length=9)\n",
       "    )\n",
       "    (4): Linear(in_features=5696, out_features=24, bias=True)\n",
       "  )\n",
       "  (de_layers): ModuleList(\n",
       "    (0): Linear(in_features=12, out_features=5696, bias=True)\n",
       "    (1): SpiralDeblock(\n",
       "      (conv): SpiralConv(32, 32, seq_length=9)\n",
       "    )\n",
       "    (2): SpiralDeblock(\n",
       "      (conv): SpiralConv(32, 16, seq_length=9)\n",
       "    )\n",
       "    (3-4): 2 x SpiralDeblock(\n",
       "      (conv): SpiralConv(16, 16, seq_length=9)\n",
       "    )\n",
       "    (5): SpiralConv(16, 3, seq_length=9)\n",
       "  )\n",
       "  (cls_sq): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       "  (reg_sq_2): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda', 1)\n",
    "# Set the path to the saved model directory\n",
    "#model_path = \"/home/jakaria/torus_bump_500_three_scale_binary_bump_variable_noise_fixed_angle/models_classification_regression_contrastive_loss_only/models/199\"\n",
    "model_path = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/hippocampus/models_attribute_age_limited_tle\"\n",
    "# Load the saved model\n",
    "model_state_dict = torch.load(f\"{model_path}/model_state_dict.pt\")\n",
    "in_channels = torch.load(f\"{model_path}/in_channels.pt\")\n",
    "out_channels = torch.load(f\"{model_path}/out_channels.pt\")\n",
    "latent_channels = torch.load(f\"{model_path}/latent_channels.pt\")\n",
    "spiral_indices_list = torch.load(f\"{model_path}/spiral_indices_list.pt\")\n",
    "up_transform_list = torch.load(f\"{model_path}/up_transform_list.pt\")\n",
    "down_transform_list = torch.load(f\"{model_path}/down_transform_list.pt\")\n",
    "std = torch.load(f\"{model_path}/std.pt\")\n",
    "mean = torch.load(f\"{model_path}/mean.pt\")\n",
    "template_face = torch.load(f\"{model_path}/faces.pt\")\n",
    "\n",
    "# Create an instance of the model\n",
    "model = AE(in_channels, out_channels, latent_channels,\n",
    "           spiral_indices_list, down_transform_list,\n",
    "           up_transform_list)\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.to(device)\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80588537f012401ebccbcd668c238e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='Disease', max=3.0, min=-3.0, step=0.5), FloatSlider(â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to calculate the magnitude of change for each vertex\n",
    "def calculate_magnitude_change(verts, initial_verts):\n",
    "    diff = np.linalg.norm(verts - initial_verts, axis=1)\n",
    "    print(diff)\n",
    "    return diff\n",
    "\n",
    "# Function to map magnitude to colors\n",
    "# Define colors for specific distance ranges\n",
    "def map_magnitude_to_colors(magnitude):\n",
    "    colors = []\n",
    "    for dist in magnitude:\n",
    "        if 0.00 <= dist < 0.001:\n",
    "            colors.append([0, 0, 1])         # Blue\n",
    "        elif 0.001 <= dist < 0.002:\n",
    "            colors.append([0.4, 0.4, 1])     # Light Blue\n",
    "        elif 0.002 <= dist < 0.005:\n",
    "            colors.append([0.4, 0.4, 1])         # White\n",
    "        elif 0.005 <= dist < 0.01:\n",
    "            colors.append([0.4, 0.4, 1])       # Light Yellow\n",
    "        else:\n",
    "            colors.append([1, 1, 0])         # Yellow\n",
    "    return colors\n",
    "# Function to move an object to the center\n",
    "def move_to_center(verts):\n",
    "    centroid = np.mean(verts, axis=0)\n",
    "    return verts - centroid\n",
    "\n",
    "def calculate_volume_voxelization(mesh):\n",
    "    voxel_grid = o3d.geometry.VoxelGrid.create_from_triangle_mesh(mesh, voxel_size=0.001)\n",
    "    voxel_count = len(voxel_grid.get_voxels())\n",
    "    voxel_volume = voxel_grid.voxel_size ** 3\n",
    "    volume = voxel_count * voxel_volume\n",
    "    return volume\n",
    "\n",
    "rotation_matrix = np.array([[np.cos(np.pi), -np.sin(np.pi), 0],\n",
    "                            [np.sin(np.pi), np.cos(np.pi), 0],\n",
    "                            [0, 0, 1]]) #z axic\n",
    "z = torch.zeros(12)\n",
    "with torch.no_grad():\n",
    "    z = z.to(device)\n",
    "    #print(z)\n",
    "    pred = model.decoder(z)\n",
    "\n",
    "    reshaped_pred_initial = (pred.view(-1, 3).cpu() * std) + mean\n",
    "    reshaped_pred_initial = reshaped_pred_initial.cpu().numpy()\n",
    "    #print(reshaped_pred.shape)\n",
    "\n",
    "verts_initial = reshaped_pred_initial\n",
    "#verts = o3d.utility.Vector3dVector(np.dot(np.asarray(verts), rotation_matrix.T))\n",
    "verts_initial = np.dot(np.asarray(verts_initial), rotation_matrix.T)\n",
    "\n",
    "plot=None\n",
    "sliders = {f'z[{i}]': FloatSlider(min=-3.0, max=3.0, step=0.5, value=0) for i in range(12)}\n",
    "sliders['z[0]'].description = 'Disease'\n",
    "sliders['z[1]'].description = 'Age'\n",
    "\n",
    "@mp.interact(**sliders)\n",
    "#@mp.interact(**{f'z[{i}]': FloatSlider(min=-2.5, max=2.5, step=0.4, value=0) for i in range(12)})\n",
    "def show(**kwargs):\n",
    "    global plot\n",
    "    global z\n",
    "    z = torch.tensor([kwargs[f'z[{i}]'] for i in range(12)])\n",
    "    with torch.no_grad():\n",
    "        z = z.to(device)\n",
    "        #print(z)\n",
    "        pred = model.decoder(z)\n",
    "\n",
    "        reshaped_pred = (pred.view(-1, 3).cpu() * std) + mean\n",
    "        reshaped_pred = reshaped_pred.cpu().numpy()\n",
    "        #print(reshaped_pred.shape)\n",
    "\n",
    "    verts = reshaped_pred\n",
    "    #verts = o3d.utility.Vector3dVector(np.dot(np.asarray(verts), rotation_matrix.T))\n",
    "    verts = np.dot(np.asarray(verts), rotation_matrix.T)\n",
    "\n",
    "    pcd = o3d.io.read_triangle_mesh('/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/hippocampus/template/template.ply')\n",
    "    faces = np.asarray(pcd.triangles)\n",
    "    initial_verts = np.asarray(pcd.vertices)\n",
    "    #print(verts)\n",
    "    #print(faces)\n",
    "    '''\n",
    "    # Define a threshold for separating the objects based on x-values\n",
    "    x_threshold = 0.0\n",
    "\n",
    "    # Separate vertices and faces for the first object (x < x_threshold)\n",
    "    verts_object1 = verts[verts[:, 0] < x_threshold]\n",
    "    faces_object1 = [face for face in faces if (verts[face, 0] < x_threshold).all()]\n",
    "\n",
    "    # Separate vertices and faces for the second object (x >= x_threshold)\n",
    "    verts_object2 = verts[verts[:, 0] >= x_threshold]\n",
    "    faces_object2 = [face for face in faces if (verts[face, 0] >= x_threshold).all()]\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    verts_object1 = np.array(verts_object1)\n",
    "    faces_object1 = np.array(faces_object1)\n",
    "    verts_object2 = np.array(verts_object2)\n",
    "    faces_object2 = np.array(faces_object2)\n",
    "\n",
    "\n",
    "    print(verts_object1.shape)\n",
    "    print(faces_object1.shape)\n",
    "\n",
    "    verts_object1 = move_to_center(verts_object1)\n",
    "\n",
    "    mesh = o3d.geometry.TriangleMesh()\n",
    "    mesh.vertices = o3d.utility.Vector3dVector(verts_object2)\n",
    "    mesh.triangles = o3d.utility.Vector3iVector(faces_object2)\n",
    "    volume = calculate_volume_voxelization(mesh)\n",
    "    print(volume)\n",
    "\n",
    "    #o3d.visualization.draw_geometries([verts_object1])\n",
    "    #o3d.visualization.draw_plotly([verts_object1])\n",
    "    \n",
    "    #with np.printoptions(threshold=np.inf):\n",
    "        #print(verts_object1)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Calculate magnitude of change\n",
    "    magnitude = calculate_magnitude_change(verts, verts_initial)\n",
    "\n",
    "    # Map magnitude to colors\n",
    "    colors = map_magnitude_to_colors(magnitude)\n",
    "    colors = np.asarray(colors)\n",
    "\n",
    "\n",
    "    white_color = [1.0, 1.0, 1.0]\n",
    "    grey_color = [0.5, 0.5, 0.5]\n",
    "\n",
    "    if plot is None:\n",
    "        #plot = mp.plot(verts_object1)\n",
    "        plot = mp.plot(verts, faces, c=colors, return_plot=True)\n",
    "    else:\n",
    "        with HiddenPrints():\n",
    "            #plot.update_object(vertices=verts, faces=faces)\n",
    "            plot.update_object(vertices=verts, faces=faces, colors=colors)\n",
    "        display(plot._renderer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to move an object to the center\n",
    "def move_to_center(verts):\n",
    "    centroid = np.mean(verts, axis=0)\n",
    "    return verts - centroid\n",
    "\n",
    "def calculate_volume_voxelization(mesh):\n",
    "    voxel_grid = o3d.geometry.VoxelGrid.create_from_triangle_mesh(mesh, voxel_size=0.1)\n",
    "    voxel_count = len(voxel_grid.get_voxels())\n",
    "    voxel_volume = voxel_grid.voxel_size ** 3\n",
    "    volume = voxel_count * voxel_volume\n",
    "    return volume\n",
    "\n",
    "rotation_matrix = np.array([[np.cos(np.pi), -np.sin(np.pi), 0],\n",
    "                            [np.sin(np.pi), np.cos(np.pi), 0],\n",
    "                            [0, 0, 1]]) #z axic\n",
    "z = torch.zeros(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/hippocampus/models_attribute_age_limited_tle/angles.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m latent_channels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/latent_channels.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m angles \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/angles.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_geo/lib/python3.10/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_geo/lib/python3.10/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_geo/lib/python3.10/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/hippocampus/models_attribute_age_limited_tle/angles.pt'"
     ]
    }
   ],
   "source": [
    "latent_channels = torch.load(f\"{model_path}/latent_channels.pt\")\n",
    "angles = torch.load(f\"{model_path}/angles.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0500, 0.1000, 0.8000],\n",
      "        [0.0500, 0.0000, 0.0500, 0.7500],\n",
      "        [0.1000, 0.0500, 0.0000, 0.7000],\n",
      "        [0.8000, 0.7500, 0.7000, 0.0000]])\n",
      "tensor([[ True,  True, False, False],\n",
      "        [ True,  True,  True, False],\n",
      "        [False,  True,  True, False],\n",
      "        [False, False, False,  True]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Sample flattened labels\n",
    "y_expanded = torch.tensor([[1.0, 0.95, 0.9, 0.2]])\n",
    "threshold = 0.05001\n",
    "\n",
    "abs_diff_matrix = torch.abs(y_expanded - y_expanded.t())\n",
    "same_class_mask = abs_diff_matrix <= threshold\n",
    "\n",
    "print(abs_diff_matrix)\n",
    "print(same_class_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_root = \"//home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/hippocampus/models_contrastive_inhib\"\n",
    "trials = torch.load(f\"{model_path_root}/intermediate_trials.pt\")\n",
    "trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import meshplot as mp\n",
    "from ipywidgets import interact, FloatSlider\n",
    "from scipy.spatial import distance\n",
    "import open3d as o3d\n",
    "from skimage import measure\n",
    "from contextlib import contextmanager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate distance between two point clouds (meshes)\n",
    "def calculate_distance(mesh1, mesh2):\n",
    "    return distance.directed_hausdorff(mesh1.vertices, mesh2.vertices)[0]\n",
    "\n",
    "# Create a directory to save plots and results\n",
    "output_dir = \"/home/jakaria/save_plots_ms_range\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to save plots\n",
    "def save_plot(plot, filename):\n",
    "    plot.save(os.path.join(output_dir, filename))\n",
    "\n",
    "def calculate_volume_voxelization(mesh):\n",
    "    voxel_grid = o3d.geometry.VoxelGrid.create_from_triangle_mesh(mesh, voxel_size=0.001)\n",
    "    voxel_count = len(voxel_grid.get_voxels())\n",
    "    voxel_volume = voxel_grid.voxel_size ** 3\n",
    "    volume = voxel_count * voxel_volume\n",
    "    return volume\n",
    "\n",
    "white_color = [1.0, 1.0, 1.0]\n",
    "grey_color = [0.5, 0.5, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize, save plots, and calculate distances and volumes\n",
    "def visualize_and_save(z0, z1):\n",
    "    global plot\n",
    "    global z\n",
    "\n",
    "    z[0] = z0\n",
    "    z[1] = z1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z = z.to(device)\n",
    "        pred = model.decoder(z)\n",
    "\n",
    "        reshaped_pred = (pred.view(-1, 3).cpu() * std) + mean\n",
    "        verts = reshaped_pred.cpu().numpy()\n",
    "\n",
    "    verts = np.dot(np.asarray(verts), rotation_matrix.T)\n",
    "\n",
    "    pcd = o3d.io.read_triangle_mesh('/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/hippocampus/template/template.ply')\n",
    "    faces = np.asarray(pcd.triangles)\n",
    "\n",
    "    white_color = [1.0, 1.0, 1.0]\n",
    "    grey_color = [0.5, 0.5, 0.5]\n",
    "     \n",
    "    #mp.subplot(verts, faces, c=np.array(white_color), s=[2, 2, 0])\n",
    "    #plot = mp.plot(verts, faces, c=np.array(white_color), return_plot=True)\n",
    "    #save_plot(plot, f'z0_{z0:.1f}_z1_{z1:.1f}.png')\n",
    "    #print(verts.shape, faces.shape)\n",
    "    return verts, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.769492745399475 -30.13582706451416\n",
      "20.611996650695804 -20.85673034191132\n",
      "4.492974653840065 -4.3707940727472305\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4946.27348786492\n",
      "4946.27348786492\n",
      "29.61395502090454 -30.13048768043518\n",
      "20.264525413513187 -21.088930964469906\n",
      "4.90114688873291 -4.380163922905922\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "5029.688542521696\n",
      "5029.688542521696\n",
      "29.764416217803955 -30.14093041419983\n",
      "20.53082942962647 -20.774751305580143\n",
      "4.456835985183716 -4.362678527832031\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4895.500491917255\n",
      "4895.500491917255\n",
      "29.604247212409973 -30.145111083984375\n",
      "20.146316885948185 -21.02820217609406\n",
      "4.8659637570381165 -4.3561723083257675\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4973.7629018845255\n",
      "4973.7629018845255\n",
      "29.759291410446167 -30.146069526672363\n",
      "20.44864654541016 -20.694925189018253\n",
      "4.4193219393491745 -4.356484487652779\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4844.807899147368\n",
      "4844.807899147368\n",
      "29.59429621696472 -30.16010284423828\n",
      "20.029715895652775 -20.97084760665894\n",
      "4.828977212309837 -4.333098977804184\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4917.975151073241\n",
      "4917.97515107324\n",
      "29.75412368774414 -30.151240825653076\n",
      "20.363740324974064 -20.61954259872437\n",
      "4.3803621083498 -4.35054786503315\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4794.18841252841\n",
      "4794.18841252841\n",
      "29.584107398986816 -30.17542004585266\n",
      "19.913170337677006 -20.9112560749054\n",
      "4.7903332859277725 -4.31063137948513\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4862.3390807158785\n",
      "4862.3390807158785\n",
      "29.748947024345398 -30.156447887420654\n",
      "20.275588631629947 -20.540885925292972\n",
      "4.339877143502235 -4.344876855611801\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4743.678662494529\n",
      "4743.678662494529\n",
      "29.573673605918884 -30.191080570220947\n",
      "19.80067312717438 -20.849102139472965\n",
      "4.750069230794907 -4.291380941867828\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4806.874576393113\n",
      "4806.874576393113\n",
      "29.74375069141388 -30.161672830581665\n",
      "20.184198617935184 -20.46461999416351\n",
      "4.297607392072678 -4.339441284537315\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4693.319715543052\n",
      "4693.319715543052\n",
      "29.56304669380188 -30.208454132080078\n",
      "19.689568877220157 -20.783810019493107\n",
      "4.708303138613701 -4.278320446610451\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4751.581198458087\n",
      "4751.581198458087\n",
      "29.73849892616272 -30.16691565513611\n",
      "20.08979737758637 -20.40815412998199\n",
      "4.253227263689041 -4.334242269396782\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4643.111302534409\n",
      "4643.111302534409\n",
      "29.552255272865295 -30.226693153381348\n",
      "19.576542377471927 -20.714877247810367\n",
      "4.665115475654602 -4.272885620594025\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4696.442713897304\n",
      "4696.442713897304\n",
      "29.73318099975586 -30.172194242477417\n",
      "19.9921327829361 -20.365390777587887\n",
      "4.206420481204987 -4.329222068190575\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4593.050287674506\n",
      "4593.050287674506\n",
      "29.54126000404358 -30.245025157928467\n",
      "19.461706280708317 -20.642235875129703\n",
      "4.620349407196045 -4.267765209078789\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4641.447166915905\n",
      "4641.447166915905\n",
      "29.727782607078552 -30.17780900001526\n",
      "19.891065359115604 -20.321812033653256\n",
      "4.157295823097229 -4.324383661150932\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4543.176990227244\n",
      "4543.176990227244\n",
      "29.530069828033447 -30.26340365409851\n",
      "19.34538781642914 -20.57386100292206\n",
      "4.57364059984684 -4.262937605381012\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4586.607807892608\n",
      "4586.607807892608\n",
      "29.722284078598022 -30.184428691864014\n",
      "19.78677034378052 -20.275608301162716\n",
      "4.107057303190231 -4.323993995785713\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4493.546419733874\n",
      "4493.546419733874\n",
      "29.51872944831848 -30.28175711631775\n",
      "19.240543842315677 -20.502621531486515\n",
      "4.525095969438553 -4.258360713720322\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4531.975836059944\n",
      "4531.975836059944\n",
      "29.716681838035583 -30.191084146499634\n",
      "19.67935681343079 -20.22669732570648\n",
      "4.057710245251656 -4.325489699840546\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4444.2077799795\n",
      "4444.2077799795\n",
      "29.507253170013428 -30.29993176460266\n",
      "19.13759529590607 -20.42830288410187\n",
      "4.475221782922745 -4.25405278801918\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4477.60055507441\n",
      "4477.60055507441\n",
      "29.710979461669922 -30.19776463508606\n",
      "19.572452902793888 -20.17493069171905\n",
      "4.0100641548633575 -4.327138513326645\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4395.181444248651\n",
      "4395.181444248651\n",
      "29.49566423892975 -30.317806005477905\n",
      "19.034780859947208 -20.351818799972538\n",
      "4.424180835485458 -4.256968945264816\n",
      "(6378, 3)\n",
      "True\n",
      "True\n",
      "4423.556246280776\n",
      "4423.556246280777\n"
     ]
    }
   ],
   "source": [
    "# Sample and save plots for different z[0] values while fixing z[1]\n",
    "verts_all = []\n",
    "faces_all = []\n",
    "for z1_value in np.arange(-3, 3, 0.5):\n",
    "        for z0_value in [-1.5, 1.5]:\n",
    "             verts, faces = visualize_and_save(z0_value, z1_value)\n",
    "             verts_all.append(verts)\n",
    "             faces_all.append(faces)\n",
    "             scalar_values = np.array([60, 60, 50])\n",
    "             verts = verts * scalar_values\n",
    "             print(max(verts[:, 0]), min(verts[:, 0]))\n",
    "             print(max(verts[:, 1]), min(verts[:, 1]))\n",
    "             print(max(verts[:, 2]), min(verts[:, 2]))\n",
    "             mesh = o3d.geometry.TriangleMesh()\n",
    "             mesh.vertices = o3d.utility.Vector3dVector(verts)\n",
    "             mesh.triangles = o3d.utility.Vector3iVector(faces)\n",
    "\n",
    "             print(np.asanyarray(mesh.vertices).shape)\n",
    "             print(mesh.is_orientable())\n",
    "             print(mesh.is_watertight())\n",
    "             \n",
    "             #mesh.orient_triangles()\n",
    "             #volume = calculate_volume_voxelization(mesh)\n",
    "             print(mesh.get_volume())\n",
    "             volume = mesh.get_volume()\n",
    "             #print(mesh.get_max_bound(), mesh.get_min_bound())\n",
    "             print(volume)\n",
    "          \n",
    "             #Save volumes to a text file \n",
    "             with open(os.path.join(output_dir, 'volumes.txt'), 'a') as f:\n",
    "                  f.write(f'z0_{z0_value:.1f}_z1_{z1_value:.1f}: {volume:.1f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample and save plots for different z0 and z1 values\n",
    "volume_z0_m1 = []\n",
    "volume_z0_p1 = []\n",
    "volume_differences = []\n",
    "\n",
    "# Define the range and increment for z1 values\n",
    "z1_start = -1.2\n",
    "z1_end = 1.3\n",
    "z1_increment = 0.02\n",
    "\n",
    "# Define the ranges for which you want to calculate average volumes\n",
    "z1_ranges = [\n",
    "    (-1.2, -0.8),\n",
    "    (-0.8, -0.4),\n",
    "    (-0.4, 0.0),\n",
    "    (0.0, 0.4),\n",
    "    (0.4, 0.8),\n",
    "    (0.8, 1.2),\n",
    "]\n",
    "\n",
    "for z0_value in [-1.5, 1.5]:\n",
    "    for z1_range in z1_ranges:\n",
    "        z1_range_start, z1_range_end = z1_range\n",
    "        volumes_for_z1_range = []\n",
    "\n",
    "        for z1_value in np.arange(z1_range_start, z1_range_end + z1_increment, z1_increment):\n",
    "            verts, faces = visualize_and_save(z0_value, z1_value)\n",
    "            #verts_all.append(verts)\n",
    "            #faces_all.append(faces)\n",
    "            mesh = o3d.geometry.TriangleMesh()\n",
    "            mesh.vertices = o3d.utility.Vector3dVector(verts)\n",
    "            mesh.triangles = o3d.utility.Vector3iVector(faces)\n",
    "            volume = mesh.get_volume()*316800\n",
    "            volumes_for_z1_range.append(volume)\n",
    "\n",
    "        # Calculate and print the average volume for the current z1 range\n",
    "        average_volume = sum(volumes_for_z1_range) / len(volumes_for_z1_range)\n",
    "\n",
    "        if z0_value == -1.5:\n",
    "            volume_z0_m1.append(average_volume)\n",
    "\n",
    "        if z0_value == 1.5:\n",
    "            volume_z0_p1.append(average_volume)\n",
    "        \n",
    "        # Print and save the average volume without detailed range information\n",
    "        print(f'z0_{z0_value:.1f}_z1_range_{z1_range_start:.2f}_{z1_range_end:.2f} (Average Volume): {average_volume:.1f}')\n",
    "\n",
    "        # Save average volumes to a text file\n",
    "        with open(os.path.join(output_dir, 'average_volumes.txt'), 'a') as f:\n",
    "            f.write(f'z0_{z0_value:.1f}_z1_range_{z1_range_start:.2f}_{z1_range_end:.2f} (Average Volume): {average_volume:.1f}\\n')\n",
    "\n",
    "# Calculate and store individual volume differences for each range\n",
    "for i in range(len(z1_ranges)):\n",
    "    volume_difference = volume_z0_p1[i] - volume_z0_m1[i]\n",
    "    volume_differences.append(volume_difference)\n",
    "    print(volume_differences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_differences = []\n",
    "for i in range(len(z1_ranges)):\n",
    "    volume_difference = -(volume_z0_m1[i] - volume_z0_p1[i])\n",
    "    volume_differences.append(volume_difference)\n",
    "print(volume_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Create custom x-axis labels\n",
    "#TLE 18 to 73\n",
    "age_ranges = [\n",
    "    (18, 26),\n",
    "    (27, 35),\n",
    "    (36, 44),\n",
    "    (45, 53),\n",
    "    (54, 62),\n",
    "    (63, 71),\n",
    "]\n",
    "# Create custom x-axis labels\n",
    "x_axis_labels = [f'{start}-{end}' for start, end in age_ranges]\n",
    "volume_differences\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(volume_differences, marker='o', linestyle='-', color='b')\n",
    "plt.title('Volume Differences vs. Age Ranges')\n",
    "plt.xlabel('Age Range')\n",
    "plt.ylabel('Volume Differences ($mm^3$)')\n",
    "plt.xticks(range(len(z1_ranges)), x_axis_labels, rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    mp.plot(verts_all[i], faces_all[i], c=np.array(white_color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for saving vertices and faces\n",
    "vertices_file = os.path.join(output_dir,\"mesh_vertices.npy\")\n",
    "faces_file = os.path.join(output_dir,\"mesh_faces.npy\")\n",
    "\n",
    "\n",
    "# Save vertices and faces to separate .npy files\n",
    "np.save(vertices_file, verts_all)\n",
    "np.save(faces_file, faces_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distances between corresponding vertices\n",
    "distances = np.linalg.norm(verts_all[1] - verts_all[0], axis=1)\n",
    "\n",
    "# Create Open3D TriangleMesh objects\n",
    "mesh1 = o3d.geometry.TriangleMesh()\n",
    "mesh1.vertices = o3d.utility.Vector3dVector(verts_all[1])\n",
    "mesh1.compute_vertex_normals()\n",
    "\n",
    "mesh2 = o3d.geometry.TriangleMesh()\n",
    "mesh2.vertices = o3d.utility.Vector3dVector(verts_all[0])\n",
    "mesh2.compute_vertex_normals()\n",
    "\n",
    "# Create a color mapping based on distances\n",
    "# You can adjust the color thresholds as needed\n",
    "color_map = o3d.visualization.draw_plotly([mesh1, mesh2])\n",
    "\n",
    "# Normalize distances to the range [0, 1] for colormap mapping\n",
    "normalized_distances = (distances - distances.min()) / (distances.max() - distances.min())\n",
    "\n",
    "# Map distances to colors using the colormap\n",
    "colors = np.asarray(color_map(normalized_distances))[:, :3]  # Extract RGB values\n",
    "\n",
    "# Set the base color of mesh2 to white (or any other base color)\n",
    "mesh2.paint_uniform_color([1, 1, 1])\n",
    "\n",
    "# Assign the calculated colors to the faces of mesh2\n",
    "mesh2.vertex_colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "# Visualize both meshes\n",
    "o3d.visualization.draw_plotly([mesh1, mesh2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate distance between meshes and create color-coded plots\n",
    "z[1] = 0.2  # Set a specific value for z[1]\n",
    "distances = np.zeros((len(np.arange(-1, 1.2, 0.2)), len([-1, 1])))\n",
    "for i, z0_value in enumerate([-1, 1]):\n",
    "    for j, z1_value in enumerate(np.arange(-1, 1.2, 0.2)):\n",
    "        visualize_and_save(z0_value, z1_value)\n",
    "        mesh1 = o3d.geometry.TriangleMesh.create_from_points(verts)\n",
    "        mesh2 = o3d.geometry.TriangleMesh.create_from_points(verts)\n",
    "        distances[j, i] = calculate_distance(mesh1, mesh2)\n",
    "\n",
    "# Save distances as a color-coded plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(distances, cmap='viridis', origin='lower', extent=[-1, 1, -1, 1])\n",
    "plt.colorbar(label='Distance')\n",
    "plt.xlabel('z[0]')\n",
    "plt.ylabel('z[1]')\n",
    "plt.title('Distance Heatmap')\n",
    "plt.savefig(os.path.join(output_dir, 'distance_heatmap.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.interp(0.77, [0,1], [1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.interp(0.15, [0,1], [1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.load('/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/hippocampus/labels.pt')\n",
    "print(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
