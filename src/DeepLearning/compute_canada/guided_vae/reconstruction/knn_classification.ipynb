{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from reconstruction import AE\n",
    "from datasets import MeshData\n",
    "from utils import utils, DataLoader, mesh_sampling, sap\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from skimage import measure\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, FloatSlider\n",
    "from IPython.display import display\n",
    "import meshplot as mp\n",
    "import os, sys\n",
    "from math import ceil\n",
    "from scipy.ndimage import zoom\n",
    "import open3d as o3d\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meshplot left an annoying print statement in their code. Using this context manager to supress it...\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE(\n",
       "  (en_layers): ModuleList(\n",
       "    (0): SpiralEnblock(\n",
       "      (conv): SpiralConv(3, 32, seq_length=9)\n",
       "    )\n",
       "    (1-2): 2 x SpiralEnblock(\n",
       "      (conv): SpiralConv(32, 32, seq_length=9)\n",
       "    )\n",
       "    (3): SpiralEnblock(\n",
       "      (conv): SpiralConv(32, 64, seq_length=9)\n",
       "    )\n",
       "    (4): Linear(in_features=11392, out_features=32, bias=True)\n",
       "  )\n",
       "  (de_layers): ModuleList(\n",
       "    (0): Linear(in_features=16, out_features=11392, bias=True)\n",
       "    (1): SpiralDeblock(\n",
       "      (conv): SpiralConv(64, 64, seq_length=9)\n",
       "    )\n",
       "    (2): SpiralDeblock(\n",
       "      (conv): SpiralConv(64, 32, seq_length=9)\n",
       "    )\n",
       "    (3-4): 2 x SpiralDeblock(\n",
       "      (conv): SpiralConv(32, 32, seq_length=9)\n",
       "    )\n",
       "    (5): SpiralConv(32, 3, seq_length=9)\n",
       "  )\n",
       "  (cls_sq): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       "  (reg_sq_2): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (3): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (4): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Linear(in_features=8, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda', 1)\n",
    "# Set the path to the saved model directory\n",
    "#model_path = \"/home/jakaria/torus_bump_500_three_scale_binary_bump_variable_noise_fixed_angle/models_classification_regression_only_correlation_loss/models/65\"\n",
    "#model_path = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/torus/models_contrastive_inhib/146\"\n",
    "#model_path = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/torus/models_guided/30\"# Load the saved model\n",
    "model_path = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/hippocampus/models_guided/44\"\n",
    "model_state_dict = torch.load(f\"{model_path}/model_state_dict.pt\")\n",
    "in_channels = torch.load(f\"{model_path}/in_channels.pt\")\n",
    "out_channels = torch.load(f\"{model_path}/out_channels.pt\")\n",
    "latent_channels = torch.load(f\"{model_path}/latent_channels.pt\")\n",
    "spiral_indices_list = torch.load(f\"{model_path}/spiral_indices_list.pt\")\n",
    "up_transform_list = torch.load(f\"{model_path}/up_transform_list.pt\")\n",
    "down_transform_list = torch.load(f\"{model_path}/down_transform_list.pt\")\n",
    "std = torch.load(f\"{model_path}/std.pt\")\n",
    "mean = torch.load(f\"{model_path}/mean.pt\")\n",
    "template_face = torch.load(f\"{model_path}/faces.pt\")\n",
    "\n",
    "# Create an instance of the model\n",
    "model = AE(in_channels, out_channels, latent_channels,\n",
    "           spiral_indices_list, down_transform_list,\n",
    "           up_transform_list)\n",
    "model.load_state_dict(model_state_dict)\n",
    "model.to(device)\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/utils/read.py:15: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402411778/work/torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  y = torch.Tensor([labels[subject]])\n",
      " 16%|█▋        | 825/5000 [00:25<02:07, 32.84it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m test_exp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbareteeth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterpolation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m meshdata \u001b[38;5;241m=\u001b[39m \u001b[43mMeshData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtemplate_fp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mtest_exp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_exp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(meshdata\u001b[38;5;241m.\u001b[39mtrain_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m     12\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(meshdata\u001b[38;5;241m.\u001b[39mtest_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "File \u001b[0;32m~/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/datasets/meshdata.py:27\u001b[0m, in \u001b[0;36mMeshData.__init__\u001b[0;34m(self, root, template_fp, split, test_exp, transform, pre_transform)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/datasets/meshdata.py:30\u001b[0m, in \u001b[0;36mMeshData.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCoMA\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdata_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                              \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtest_exp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_exp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_dataset \u001b[38;5;241m=\u001b[39m CoMA(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot,\n\u001b[1;32m     38\u001b[0m                             data_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m                             split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit,\n\u001b[1;32m     40\u001b[0m                             test_exp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_exp,\n\u001b[1;32m     41\u001b[0m                             transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform,\n\u001b[1;32m     42\u001b[0m                             pre_transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_transform)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_dataset \u001b[38;5;241m=\u001b[39m CoMA(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot,\n\u001b[1;32m     45\u001b[0m                              data_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     46\u001b[0m                              split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit,\n\u001b[1;32m     47\u001b[0m                              test_exp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_exp,\n\u001b[1;32m     48\u001b[0m                              transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform,\n\u001b[1;32m     49\u001b[0m                              pre_transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_transform)\n",
      "File \u001b[0;32m~/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/datasets/coma.py:50\u001b[0m, in \u001b[0;36mCoMA.__init__\u001b[0;34m(self, root, data_split, split, test_exp, transform, pre_transform)\u001b[0m\n\u001b[1;32m     40\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(osp\u001b[38;5;241m.\u001b[39mjoin(root, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit))\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# if self.split == 'extrapolation':\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#     if self.test_exp not in self.categories:\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#         raise RuntimeError(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m#         os.makedirs(\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m#             osp.join(root, 'processed', self.split, self.test_exp))\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_split \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     53\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_paths[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_geo/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:57\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     51\u001b[0m     root: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     log: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     56\u001b[0m ):\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_geo/lib/python3.10/site-packages/torch_geometric/data/dataset.py:97\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download()\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_process:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_geo/lib/python3.10/site-packages/torch_geometric/data/dataset.py:230\u001b[0m, in \u001b[0;36mDataset._process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m    229\u001b[0m makedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir)\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m path \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_transform.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    233\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(_repr(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_transform), path)\n",
      "File \u001b[0;32m~/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/datasets/coma.py:131\u001b[0m, in \u001b[0;36mCoMA.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m     val_data_list\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m subject \u001b[38;5;129;01min\u001b[39;00m X_train:\n\u001b[0;32m--> 131\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mread_mesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     train_data_list\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m#train_val_test_files[\"train\"].append(fp.split(\"/\")[-1])\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m#raise RuntimeError('ERROR...')\u001b[39;00m\n",
      "File \u001b[0;32m~/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/utils/read.py:13\u001b[0m, in \u001b[0;36mread_mesh\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     10\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([face[:\u001b[38;5;241m2\u001b[39m], face[\u001b[38;5;241m1\u001b[39m:], face[::\u001b[38;5;241m2\u001b[39m]], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     11\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m to_undirected(edge_index)\n\u001b[0;32m---> 13\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/raw/hippocampus/labels.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m subject \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     15\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([labels[subject]])\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_geo/lib/python3.10/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_geo/lib/python3.10/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "template_fp = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA/template/template.ply\"\n",
    "data_fp = \"/home/jakaria/Explaining_Shape_Variability/src/DeepLearning/compute_canada/guided_vae/data/CoMA\"\n",
    "test_exp = \"bareteeth\"\n",
    "split = \"interpolation\"\n",
    "\n",
    "meshdata = MeshData(data_fp,\n",
    "                    template_fp,\n",
    "                    split=split,\n",
    "                    test_exp=test_exp)\n",
    "\n",
    "train_loader = DataLoader(meshdata.train_dataset, batch_size=16)\n",
    "test_loader = DataLoader(meshdata.test_dataset, batch_size=16)\n",
    "\n",
    "angles_train = []\n",
    "thick_train = []\n",
    "latent_codes_train = []\n",
    "\n",
    "angles_test = []\n",
    "thick_test = []\n",
    "latent_codes_test = []\n",
    "\n",
    "single_latent = True\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(train_loader):\n",
    "        #print(\"train...\")\n",
    "        x = data.x.to(device)\n",
    "        y = data.y.to(device)\n",
    "        pred, mu, log_var, re, re2 = model(x)\n",
    "\n",
    "        z = model.reparameterize(mu, log_var)\n",
    "        if single_latent:\n",
    "            z = z[:,1]\n",
    "        latent_codes_train.append(z)\n",
    "        angles_train.append(y[:, :, 0])\n",
    "        thick_train.append(y[:, :, 2])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        #print(\"test...\")\n",
    "        x = data.x.to(device)\n",
    "        y = data.y.to(device)\n",
    "        pred, mu, log_var, re, re2 = model(x)\n",
    "\n",
    "        z = model.reparameterize(mu, log_var)\n",
    "        if single_latent:\n",
    "            z = z[:,1]\n",
    "        latent_codes_test.append(z)\n",
    "        angles_test.append(y[:, :, 0])\n",
    "        thick_test.append(y[:, :, 2])\n",
    "\n",
    "latent_codes_train = torch.concat(latent_codes_train)\n",
    "if single_latent:\n",
    "    latent_codes_train = latent_codes_train.cpu().numpy().reshape(-1, 1)\n",
    "else:\n",
    "    latent_codes_train = latent_codes_train.cpu().numpy()\n",
    "angles_train = torch.concat(angles_train).view(-1,1)\n",
    "angles_train = angles_train.view(-1).cpu().numpy()\n",
    "thick_train = torch.concat(thick_train).view(-1,1)\n",
    "thick_train = thick_train.view(-1).cpu().numpy()\n",
    "\n",
    "latent_codes_test = torch.concat(latent_codes_test)\n",
    "if single_latent:\n",
    "    latent_codes_test = latent_codes_test.cpu().numpy().reshape(-1, 1)\n",
    "else:   \n",
    "    latent_codes_test = latent_codes_test.cpu().numpy()\n",
    "angles_test = torch.concat(angles_test).view(-1,1)\n",
    "angles_test = angles_test.view(-1).cpu().numpy()\n",
    "thick_test = torch.concat(thick_test).view(-1,1)\n",
    "thick_test = thick_test.view(-1).cpu().numpy()\n",
    "\n",
    "# Train a classifier on the latent codes\n",
    "X_train = latent_codes_train\n",
    "y_train = thick_train\n",
    "X_test = latent_codes_test\n",
    "y_test = thick_test\n",
    "\n",
    "#knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn = KNeighborsRegressor(n_neighbors=12)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "#print(y_test[:10], y_pred[:10])\n",
    "#print(latent_codes_test[:10], y_test[:10])\n",
    "\n",
    "#print(y_test, y_pred)\n",
    "#print(\"Accuracy of the KNN for binary bump: \", accuracy_score(y_test, y_pred[:len(y_test)]))\n",
    "print(\"MSE of the KNN for thickness: \", mean_squared_error(y_test, y_pred[:len(y_test)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of the Linear Regression for thickness:  0.0017567916\n"
     ]
    }
   ],
   "source": [
    "LR = LinearRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "print(\"MSE of the Linear Regression for thickness: \", mean_squared_error(y_test, y_pred[:len(y_test)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
